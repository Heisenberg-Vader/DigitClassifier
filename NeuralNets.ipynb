{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFoAqZzDGitF"
      },
      "source": [
        "#**MNIST Handwritten digits predictor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00q_yTDSGaIO"
      },
      "outputs": [],
      "source": [
        "# Import all the required libraries.\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D-L_xoqHUqo",
        "outputId": "f0b61cc5-0546-4a4a-8fb4-69de3e668486"
      },
      "outputs": [],
      "source": [
        "# Loading the MNIST dataset into the training and testing sets.\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwxwH-2ZHaFx"
      },
      "outputs": [],
      "source": [
        "# Pre-processing dataset\n",
        "X_train, X_test = X_train/255.0, X_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRcHcQe7Hhku",
        "outputId": "f5d6b8af-4177-482e-c0b9-1db6b2be500c"
      },
      "outputs": [],
      "source": [
        "# Reshaping the dataset\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYNx6BJ5QvB3",
        "outputId": "ee528cdc-fd75-4406-89e1-839ed47c0c5c"
      },
      "outputs": [],
      "source": [
        "# Define rotation angles\n",
        "angles = [0, 45, 90, 135, 180, 225, 270, 315]\n",
        "\n",
        "# Prepare arrays to store augmented data\n",
        "X_augmented = []\n",
        "y_augmented = []\n",
        "\n",
        "# Rotate each image at all angles\n",
        "for i in range(len(X_train)):\n",
        "    img = np.expand_dims(X_train[i], axis=0)  # Shape: (1, 28, 28, 1)\n",
        "\n",
        "    for angle in angles:\n",
        "        augmented_img = ImageDataGenerator(rotation_range=angle).flow(img, batch_size=1).__next__()[0]\n",
        "        X_augmented.append(augmented_img)\n",
        "        y_augmented.append(y_train[i])  # Keep the same label\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X_augmented = np.array(X_augmented)\n",
        "y_augmented = np.array(y_augmented)\n",
        "\n",
        "# Shuffle the dataset to mix rotations\n",
        "indices = np.arange(len(X_augmented))\n",
        "np.random.shuffle(indices)\n",
        "X_augmented, y_augmented = X_augmented[indices], y_augmented[indices]\n",
        "\n",
        "# Print new dataset size\n",
        "print(f\"New dataset size: {X_augmented.shape}, {y_augmented.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VurN9FbIKlB",
        "outputId": "7f751790-5a80-448a-d1c1-f255a8ac6101"
      },
      "outputs": [],
      "source": [
        "# Building the sequential neural networks model\n",
        "model = models.Sequential([\n",
        "    # Convolutional layer with 32 filters, 3x3 kernel, ReLU activation, and input shape will be 28x28x1\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "\n",
        "    # Max Pooling layer\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Another convolutional layer with 64 filters\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    # Max Pooling layer\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten the 3D output to 1D\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # Fully connected layer with 64 units\n",
        "    layers.Dense(64, activation='relu'),\n",
        "\n",
        "    # Output layer with 10 layers (one for each digit), softmax for probability distribution\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkQ1wXb0Jlqb"
      },
      "outputs": [],
      "source": [
        "# Compiling the sequential model created above\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h018xxAXJxez",
        "outputId": "0817a8b7-9d1e-48ea-e927-8a0cd39761ef"
      },
      "outputs": [],
      "source": [
        "# Fitting the data into the model\n",
        "history = model.fit(X_augmented, y_augmented, epochs=5, validation_data=(X_test, y_test))\n",
        "# history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSA8omFjJ8uW",
        "outputId": "f8ed09f4-29af-41b8-b014-bdb75fcfc16c"
      },
      "outputs": [],
      "source": [
        "# Calculating the test loss and test accuracy\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "bZorI9qnOqZX",
        "outputId": "1ffd348b-15b3-481c-d79b-1d1aa81f45e5"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "impath = \"img.png\"\n",
        "img = cv2.imread(impath, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "img = cv2.resize(img, (28, 28))\n",
        "img = img/255.0\n",
        "\n",
        "img = img.reshape((1, 28, 28, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc2yOMxXKMKg",
        "outputId": "ef066c27-485f-4845-b517-9680e1dd5533"
      },
      "outputs": [],
      "source": [
        "# Making predictions using the above model\n",
        "predictions = model.predict(img)\n",
        "# print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "U6Dk1TD9KVb1",
        "outputId": "29281caf-7dbb-4c2f-d4a0-63f7e57240d3"
      },
      "outputs": [],
      "source": [
        "# Showing the predicted image\n",
        "probabilities = model.predict(img)[0]\n",
        "if max(probabilities) < 0.6:  # Threshold set to 0.6\n",
        "    plt.imshow(img.reshape(28, 28), cmap='gray')\n",
        "    plt.title(f\"Predicted label: None (uncertain)\")\n",
        "    plt.show()\n",
        "else:\n",
        "    plt.imshow(img.reshape(28, 28), cmap='gray')\n",
        "    plt.title(f\"Predicted label: {np.argmax(predictions)}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "4BFAtzPHKj8L",
        "outputId": "36cf6774-12e0-455a-bff3-419a913db5c7"
      },
      "outputs": [],
      "source": [
        "# Plotting training and validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6sIAcDGPd2R",
        "outputId": "b1541967-ffc9-4535-dd5f-29f8dca9fa6c"
      },
      "outputs": [],
      "source": [
        "# Calculating the f1 score of this model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "f1 = f1_score(y_test, y_pred_labels, average='macro')\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ]
<<<<<<< HEAD
    }
=======
    },
>>>>>>> 1aaac8c498acdfde6b953aeb08758b2b8b53ffc1
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bqML2cOXhC5T"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
